{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import AgglomerativeClustering, OPTICS\n",
    "\n",
    "\n",
    "import predictive_clustering,utils"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T12:37:34.252194100Z",
     "start_time": "2024-04-24T12:37:33.088061400Z"
    }
   },
   "id": "4ac617fe95313575",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generating the Ordered Documents for the best clusters of each type\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6036262a90786b9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "baseline = pd.read_excel(\"RETOS_BEBRASK_Baseline.xlsx\")\n",
    "scales = pd.read_excel(\"filled_scales_BEBRASK_RETOS.xlsx\")\n",
    "scaled_df = pd.read_excel(\"baseline_scaled.xlsx\")\n",
    "scaled_transformed_df = pd.read_excel(\"count_scaled_transformed.xlsx\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T12:37:35.015332Z",
     "start_time": "2024-04-24T12:37:34.257214800Z"
    }
   },
   "id": "c13edd7618fe1a21",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Grouping the metrics that will be evaluated from scales for the BEBRASK and RETOS dataset (as the rest were no used\n",
    "#or contain to many NaNs\n",
    "PANAS = [\"PA\", \"NA.\"]\n",
    "ERQ = [\"ERQ_CR\", \"ERQ_ES\"]\n",
    "UPPSP = [\"UPPSP_NU\", \"UPPSP_PU\", \"UPPSP_SS\", \"UPPSP_PMD\", \"UPPSP_PSV\"]\n",
    "BIS_BAS = [\"BIS\", \"BAS_D\", \"BAS_RR\", \"BAS_FS\"]\n",
    "TEPS = [\"TEPS_AF\", \"TEPS_CF\"]\n",
    "SHS = [\"SHS\"]\n",
    "FS = [\"FS\"]\n",
    "LOTR = [\"LOT_R\"]\n",
    "RRQ = [\"RRQ_Rum\", \"RRQ_Ref\"]\n",
    "ASI3 = [\"ASI_P\", \"ASI_C\", \"ASI_S\"]\n",
    "SPQ = [\"SPQ\", \"SPQ_IR\"]\n",
    "MSSB = [\"MSSB_POS\", \"MSSB_NEG\", \"MSSB_DES\"]\n",
    "\n",
    "list_metrics = [PANAS, ERQ, UPPSP, BIS_BAS, TEPS, SHS, FS, LOTR, RRQ, ASI3, SPQ, MSSB]\n",
    "#### Importing the TimeSeries Dataset to use it for analysis later on"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T12:37:35.032385900Z",
     "start_time": "2024-04-24T12:37:35.020854300Z"
    }
   },
   "id": "34a441148726a5ab",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Baseline Hierarchical 6 clusters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "974f0d4ec4dded31"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "scaled_df = scaled_df.drop([57, 90, 123, 96, 5, 133, 43, 81]).reset_index().drop(\"index\", axis=1)\n",
    "baseline = baseline.drop([57, 90, 123, 96, 5, 133, 43, 81]).reset_index().drop(\"index\", axis=1)\n",
    "\n",
    "\n",
    "data_clusters = predictive_clustering.clustering(scaled_df, AgglomerativeClustering,\n",
    "                                                 {'n_clusters': 4, 'linkage': \"complete\"}, fit=True)\n",
    "df_cluster = pd.concat([baseline[\"Subject\"].copy(), pd.Series(data_clusters)], axis=1)\n",
    "df_cluster.columns = [\"Subject\", \"clusters\"]\n",
    "\n",
    "#AVERAGE RATING0\n",
    "\n",
    "name_output = f\"baseline_hierarchical_{4}_clusters_avg_rating.docx\"\n",
    "new_data = pd.merge(scales.copy(), df_cluster.copy(), right_on='Subject', left_on='EPRIME_CODE')\n",
    "new_data.drop(\"Subject\", axis=1, inplace=True)\n",
    "df = utils.filter_data(new_data)\n",
    "utils.create_word(df, list_metrics, name_output, df_scales=scales, cluster_order=[3,1,0,2])\n",
    "\n",
    "#CORRELATION\n",
    "\n",
    "name_output = f\"baseline_hierarchical_{4}_clusters_correlation.docx\"\n",
    "new_data = pd.merge(scales.copy(), df_cluster.copy(), right_on='Subject', left_on='EPRIME_CODE')\n",
    "new_data.drop(\"Subject\", axis=1, inplace=True)\n",
    "df = utils.filter_data(new_data)\n",
    "utils.create_word(df, list_metrics, name_output, df_scales=scales, cluster_order=[3,0,1,2])\n",
    "\n",
    "#DIFFERENCE MATCH\n",
    "\n",
    "name_output = f\"baseline_hierarchical_{4}_clusters_dif_match.docx\"\n",
    "new_data = pd.merge(scales.copy(), df_cluster.copy(), right_on='Subject', left_on='EPRIME_CODE')\n",
    "new_data.drop(\"Subject\", axis=1, inplace=True)\n",
    "df = utils.filter_data(new_data)\n",
    "utils.create_word(df, list_metrics, name_output, df_scales=scales, cluster_order=[1,3,0,2])\n",
    "#### Baseline OPTICS"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T12:39:54.187237300Z",
     "start_time": "2024-04-24T12:38:59.970080800Z"
    }
   },
   "id": "70aad3f4316b2d86",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "### OPTICS Baseline 6 min sample"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3df2f3e9864dfef"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_clusters = predictive_clustering.clustering(scaled_df,OPTICS,{\"min_samples\":6, \"metric\":\"euclidean\", \"algorithm\":\"auto\"},fit=True)\n",
    "df_cluster = pd.concat([baseline[\"Subject\"].copy(),pd.Series(data_clusters)],axis=1)\n",
    "df_cluster.columns = [\"Subject\",\"clusters\"]\n",
    "\n",
    "#AVERAGE RATING0\n",
    "\n",
    "name_output = f\"baseline_optics_{6}_clusters_avg_rating.docx\"\n",
    "new_data = pd.merge(scales.copy(), df_cluster.copy(), right_on='Subject', left_on='EPRIME_CODE')\n",
    "new_data.drop(\"Subject\", axis=1, inplace=True)\n",
    "df = utils.filter_data(new_data)\n",
    "utils.create_word(df, list_metrics, name_output,df_scales= scales,cluster_order = [1,0,2,5,3,6,4])\n",
    "\n",
    "#CORRELATION\n",
    "\n",
    "name_output = f\"baseline_optics_{6}_clusters_correlation.docx\"\n",
    "new_data = pd.merge(scales.copy(), df_cluster.copy(), right_on='Subject', left_on='EPRIME_CODE')\n",
    "new_data.drop(\"Subject\", axis=1, inplace=True)\n",
    "df = utils.filter_data(new_data)\n",
    "utils.create_word(df, list_metrics, name_output,df_scales= scales,cluster_order = [5,3,1,2,4,0,6])\n",
    "\n",
    "#DIFFERENCE MATCH\n",
    "\n",
    "name_output = f\"baseline_optics_{6}_clusters_dif_match.docx\"\n",
    "new_data = pd.merge(scales.copy(), df_cluster.copy(), right_on='Subject', left_on='EPRIME_CODE')\n",
    "new_data.drop(\"Subject\", axis=1, inplace=True)\n",
    "df = utils.filter_data(new_data)\n",
    "utils.create_word(df, list_metrics, name_output,df_scales= scales,cluster_order = [0,5,1,6,3,2,4])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "139466fa31dbc5a8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hierarchical Counts 6 clusters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81d3e87432dc7a49"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_clusters = predictive_clustering.clustering(scaled_transformed_df.drop(\"Subject\",axis=1),AgglomerativeClustering,{'n_clusters':6,'linkage':\"complete\"},fit=True)\n",
    "df_cluster = pd.concat([scaled_transformed_df[\"Subject\"].copy(),pd.Series(data_clusters)],axis=1)\n",
    "df_cluster.columns = [\"Subject\",\"clusters\"]\n",
    "\n",
    "\n",
    "#AVERAGE HAPPY_0\n",
    "\n",
    "name_output = f\"count_hierarchical_{6}_clusters_happy_0.docx\"\n",
    "new_data = pd.merge(scales.copy(), df_cluster.copy(), right_on='Subject', left_on='EPRIME_CODE')\n",
    "new_data.drop(\"Subject\", axis=1, inplace=True)\n",
    "df = utils.filter_data(new_data)\n",
    "utils.create_word(df, list_metrics, name_output,df_scales= scales, cluster_order=[1, 0, 5, 2, 4, 3])\n",
    "\n",
    "#AVERAGE HAPPY_1\n",
    "\n",
    "name_output = f\"count_hierarchical_{6}_clusters_happy_1.docx\"\n",
    "new_data = pd.merge(scales.copy(), df_cluster.copy(), right_on='Subject', left_on='EPRIME_CODE')\n",
    "new_data.drop(\"Subject\", axis=1, inplace=True)\n",
    "df = utils.filter_data(new_data)\n",
    "utils.create_word(df, list_metrics, name_output,df_scales= scales, cluster_order=[4, 2, 0, 5, 1, 3])\n",
    "\n",
    "#AVERAGE SAD_0\n",
    "\n",
    "name_output = f\"count_hierarchical_{6}_clusters_sad_0.docx\"\n",
    "new_data = pd.merge(scales.copy(), df_cluster.copy(), right_on='Subject', left_on='EPRIME_CODE')\n",
    "new_data.drop(\"Subject\", axis=1, inplace=True)\n",
    "df = utils.filter_data(new_data)\n",
    "utils.create_word(df, list_metrics, name_output,df_scales= scales, cluster_order=[1, 0, 2, 4, 5, 3])\n",
    "\n",
    "#AVERAGE SAD_1\n",
    "\n",
    "name_output = f\"count_hierarchical_{6}_clusters_sad_1.docx\"\n",
    "new_data = pd.merge(scales.copy(), df_cluster.copy(), right_on='Subject', left_on='EPRIME_CODE')\n",
    "new_data.drop(\"Subject\", axis=1, inplace=True)\n",
    "df = utils.filter_data(new_data)\n",
    "utils.create_word(df, list_metrics, name_output,df_scales= scales, cluster_order=[4, 2, 0, 5, 1, 3])\n",
    "\n",
    "#AVERAGE FEAR_0\n",
    "\n",
    "name_output = f\"count_hierarchical_{6}_clusters_fear_0.docx\"\n",
    "new_data = pd.merge(scales.copy(), df_cluster.copy(), right_on='Subject', left_on='EPRIME_CODE')\n",
    "new_data.drop(\"Subject\", axis=1, inplace=True)\n",
    "df = utils.filter_data(new_data)\n",
    "utils.create_word(df, list_metrics, name_output,df_scales= scales, cluster_order=[1, 0, 2, 5, 4, 3])\n",
    "\n",
    "#AVERAGE FEAR_1\n",
    "name_output = f\"count_hierarchical_{6}_clusters_fear_1.docx\"\n",
    "new_data = pd.merge(scales.copy(), df_cluster.copy(), right_on='Subject', left_on='EPRIME_CODE')\n",
    "new_data.drop(\"Subject\", axis=1, inplace=True)\n",
    "df = utils.filter_data(new_data)\n",
    "utils.create_word(df, list_metrics, name_output,df_scales= scales, cluster_order=[2, 4, 0, 5, 1, 3])\n",
    "\n",
    "#CORRELATION\n",
    "\n",
    "name_output = f\"count_hierarchical_{6}_clusters_correlation.docx\"\n",
    "new_data = pd.merge(scales.copy(), df_cluster.copy(), right_on='Subject', left_on='EPRIME_CODE')\n",
    "new_data.drop(\"Subject\", axis=1, inplace=True)\n",
    "df = utils.filter_data(new_data)\n",
    "utils.create_word(df, list_metrics, name_output,df_scales= scales, cluster_order=[5, 2, 1, 4, 0, 3])\n",
    "\n",
    "#AVERAGE RATING0\n",
    "\n",
    "name_output = f\"count_hierarchical_{6}_clusters_dif_match.docx\"\n",
    "new_data = pd.merge(scales.copy(), df_cluster.copy(), right_on='Subject', left_on='EPRIME_CODE')\n",
    "new_data.drop(\"Subject\", axis=1, inplace=True)\n",
    "df = utils.filter_data(new_data)\n",
    "utils.create_word(df, list_metrics, name_output,df_scales= scales, cluster_order=[4, 2, 5, 0, 1, 3])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb5a676bd5b5dfd8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### OPTICS Counts 6 min sample"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3eaac29581ac836"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_clusters = predictive_clustering.clustering(scaled_transformed_df.drop(\"Subject\",axis=1),OPTICS,{\"min_samples\":6, \"metric\":\"euclidean\", \"algorithm\":\"auto\"},fit=True)\n",
    "df_cluster = pd.concat([scaled_transformed_df[\"Subject\"].copy(),pd.Series(data_clusters)],axis=1)\n",
    "df_cluster.columns = [\"Subject\",\"clusters\"]\n",
    "\n",
    "\n",
    "#AVERAGE HAPPY_0\n",
    "\n",
    "name_output = f\"count_optics_{6}_clusters_happy_0.docx\"\n",
    "new_data = pd.merge(scales.copy(), df_cluster.copy(), right_on='Subject', left_on='EPRIME_CODE')\n",
    "new_data.drop(\"Subject\", axis=1, inplace=True)\n",
    "df = utils.filter_data(new_data)\n",
    "utils.create_word(df, list_metrics, name_output,df_scales= scales, cluster_order=[2, 1, 0, 3, 4])\n",
    "\n",
    "#AVERAGE HAPPY_1\n",
    "\n",
    "name_output = f\"count_optics_{6}_clusters_happy_1.docx\"\n",
    "new_data = pd.merge(scales.copy(), df_cluster.copy(), right_on='Subject', left_on='EPRIME_CODE')\n",
    "new_data.drop(\"Subject\", axis=1, inplace=True)\n",
    "df = utils.filter_data(new_data)\n",
    "utils.create_word(df, list_metrics, name_output,df_scales= scales, cluster_order=[0, 4, 3, 1, 2])\n",
    "\n",
    "#AVERAGE SAD_0\n",
    "\n",
    "name_output = f\"count_optics_{6}_clusters_sad_0.docx\"\n",
    "new_data = pd.merge(scales.copy(), df_cluster.copy(), right_on='Subject', left_on='EPRIME_CODE')\n",
    "new_data.drop(\"Subject\", axis=1, inplace=True)\n",
    "df = utils.filter_data(new_data)\n",
    "utils.create_word(df, list_metrics, name_output,df_scales= scales, cluster_order=[2, 1, 0, 3, 4])\n",
    "\n",
    "#AVERAGE SAD_1\n",
    "\n",
    "name_output = f\"count_optics_{6}_clusters_sad_1.docx\"\n",
    "new_data = pd.merge(scales.copy(), df_cluster.copy(), right_on='Subject', left_on='EPRIME_CODE')\n",
    "new_data.drop(\"Subject\", axis=1, inplace=True)\n",
    "df = utils.filter_data(new_data)\n",
    "utils.create_word(df, list_metrics, name_output,df_scales= scales, cluster_order=[4, 0, 3, 1, 2])\n",
    "\n",
    "#AVERAGE FEAR_0\n",
    "\n",
    "name_output = f\"count_optics_{6}_clusters_fear_0.docx\"\n",
    "new_data = pd.merge(scales.copy(), df_cluster.copy(), right_on='Subject', left_on='EPRIME_CODE')\n",
    "new_data.drop(\"Subject\", axis=1, inplace=True)\n",
    "df = utils.filter_data(new_data)\n",
    "utils.create_word(df, list_metrics, name_output,df_scales= scales, cluster_order=[2, 0, 1, 3, 4])\n",
    "\n",
    "#AVERAGE FEAR_1\n",
    "name_output = f\"count_optics_{6}_clusters_fear_1.docx\"\n",
    "new_data = pd.merge(scales.copy(), df_cluster.copy(), right_on='Subject', left_on='EPRIME_CODE')\n",
    "new_data.drop(\"Subject\", axis=1, inplace=True)\n",
    "df = utils.filter_data(new_data)\n",
    "utils.create_word(df, list_metrics, name_output,df_scales= scales, cluster_order=[0, 4, 3, 1, 2])\n",
    "\n",
    "#CORRELATION\n",
    "\n",
    "name_output = f\"count_optics_{6}_clusters_correlation.docx\"\n",
    "new_data = pd.merge(scales.copy(), df_cluster.copy(), right_on='Subject', left_on='EPRIME_CODE')\n",
    "new_data.drop(\"Subject\", axis=1, inplace=True)\n",
    "df = utils.filter_data(new_data)\n",
    "utils.create_word(df, list_metrics, name_output,df_scales= scales, cluster_order=[3, 1, 4, 2, 0])\n",
    "\n",
    "#AVERAGE RATING0\n",
    "\n",
    "name_output = f\"count_optics_{6}_clusters_dif_match.docx\"\n",
    "new_data = pd.merge(scales.copy(), df_cluster.copy(), right_on='Subject', left_on='EPRIME_CODE')\n",
    "new_data.drop(\"Subject\", axis=1, inplace=True)\n",
    "df = utils.filter_data(new_data)\n",
    "utils.create_word(df, list_metrics, name_output,df_scales= scales, cluster_order=[4, 0, 3, 1, 2])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12602c58b78eefc9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
