{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-06T21:44:35.506838100Z",
     "start_time": "2024-06-06T21:44:35.482489700Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = 'cpu'#torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, file_path):\n",
    "        self.data = pd.read_excel(file_path)\n",
    "\n",
    "    def get_columns_by_keyword(self, keyword):\n",
    "        return [col for col in self.data.columns if keyword in col]\n",
    "\n",
    "    def get_datasets(self, rating_keyword, fulfilled_keyword):\n",
    "        rating_columns = self.get_columns_by_keyword(rating_keyword)\n",
    "        fulfilled_columns = self.get_columns_by_keyword(fulfilled_keyword)\n",
    "        actions_dataset = self.data[rating_columns] - 1\n",
    "        states_dataset = self.data[fulfilled_columns]\n",
    "        return actions_dataset, states_dataset\n",
    "\n",
    "\n",
    "\n",
    "class ParticipantOptimizer:\n",
    "    def __init__(self, states, actions,n_states,n_actions, initial_rewards, Rmin=-3, Rmax=3):\n",
    "        self.states = torch.tensor(states, dtype=torch.int64, device=device)\n",
    "        self.actions = torch.tensor(actions, dtype=torch.int64, device=device)\n",
    "        self.n_states = n_states\n",
    "        self.n_actions = n_actions\n",
    "\n",
    "        self.best_rewards = initial_rewards\n",
    "        self.Rmin = Rmin\n",
    "        self.Rmax = Rmax\n",
    "\n",
    "        self.conv = 0\n",
    "\n",
    "        self.list_rewards = None\n",
    "        self.old_rewards = self.list_rewards\n",
    "\n",
    "        self.beta_no_match = None\n",
    "        self.beta_match = None\n",
    "\n",
    "    def calculate_rewards_individual(self, states, actions, rewards_matrix):\n",
    "        rewards_tensor = torch.tensor(rewards_matrix, device=device)\n",
    "        probabilities = torch.nn.functional.softmax(rewards_tensor[states], dim=1)\n",
    "        selected_probabilities = probabilities.gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "        loss = -torch.sum(torch.log(selected_probabilities))\n",
    "        return loss, rewards_tensor\n",
    "\n",
    "    def find_initial_rewards(self, num_trials=100):\n",
    "        best_loss = float('inf')\n",
    "        best_rewards = None\n",
    "\n",
    "        for _ in range(num_trials):\n",
    "            trial_rewards = np.random.uniform(self.Rmin, self.Rmax, (self.n_states, self.n_actions))\n",
    "            loss, _ = self.calculate_rewards_individual(self.states, self.actions, trial_rewards)\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_rewards = trial_rewards\n",
    "        self.best_rewards = best_rewards\n",
    "\n",
    "\n",
    "    def _get_rewards_list(self, rewards =None):\n",
    "        if rewards is None:\n",
    "            rewards = self.best_rewards\n",
    "\n",
    "        rewards_list = []\n",
    "        for state, action in zip(self.states, self.actions):\n",
    "            rewards_list.append(rewards[state][action])\n",
    "\n",
    "        self.list_rewards = torch.tensor(rewards_list, dtype=torch.float32)\n",
    "\n",
    "    def optimize(self, num_iterations=150, learning_rate=0.05):\n",
    "\n",
    "\n",
    "        self.find_initial_rewards()\n",
    "\n",
    "        for m in range(num_iterations):\n",
    "            print(m)\n",
    "            beta_unconstrained_match = torch.tensor([-2.8], requires_grad=True, device=device)\n",
    "            beta_unconstrained_no_match = torch.tensor([-2.8], requires_grad=True, device=device)\n",
    "            optimizer = optim.Adam([beta_unconstrained_match, beta_unconstrained_no_match], lr=learning_rate)\n",
    "            self._get_rewards_list()\n",
    "            for epoch in range(250):\n",
    "                optimizer.zero_grad()\n",
    "                beta_match = torch.sigmoid(beta_unconstrained_match)\n",
    "                beta_no_match = torch.sigmoid(beta_unconstrained_no_match)\n",
    "\n",
    "                loss, _, probability_data= self.simulate(beta_match, beta_no_match)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            self.RandomWalk(0.05,beta_match,beta_no_match,probability_data)\n",
    "            if (self.conv == 50):\n",
    "                break\n",
    "\n",
    "        self.beta_match = beta_match\n",
    "        self.beta_no_match = beta_no_match\n",
    "\n",
    "\n",
    "\n",
    "    def perturb_rewards(self, scale=0.02):\n",
    "        perturbation = np.random.uniform(-scale, scale, self.best_rewards.shape)\n",
    "        new_rewards = np.clip(self.best_rewards + perturbation, self.Rmin, self.Rmax)\n",
    "        return new_rewards\n",
    "    def RandomWalk(self, distance, beta_match, beta_no_match, old_probability):\n",
    "        better = False\n",
    "        self.old_rewards = self.list_rewards\n",
    "        self.conv = 0\n",
    "        while(not better and self.conv < 50):\n",
    "            new_rewards_matrix = self.perturb_rewards(distance)\n",
    "            self._get_rewards_list(new_rewards_matrix)\n",
    "\n",
    "            Q_values = torch.tensor(new_rewards_matrix, requires_grad=True, device=device)\n",
    "            Q_updated = Q_values.clone()\n",
    "            new_probability_data = 1\n",
    "            new_loss = 0\n",
    "\n",
    "            for i in range(1, len(self.states)):\n",
    "\n",
    "                state = self.states[i]\n",
    "                action = self.actions[i]\n",
    "                reward = self.list_rewards[i - 1]\n",
    "                # Update Q_values on a new tensor to avoid in-place operations\n",
    "                probabilities = torch.nn.functional.softmax(Q_updated, dim=1)  # Assuming Q_updated is indexed appropriately\n",
    "                selected_probability = probabilities[state].gather(0, action)\n",
    "                new_probability_data *= selected_probability\n",
    "                new_loss -= torch.log(selected_probability)\n",
    "\n",
    "                ## Maybe different beta for sequence s0->s0, s0->s1, s1->s0, s1->s1\n",
    "                if (self.states[i - 1] == 0):\n",
    "                    beta = beta_no_match\n",
    "                else:\n",
    "                    beta = beta_match\n",
    "                new_Q_value = beta * (Q_updated[state, action].clone() - reward) + Q_updated[state, action].clone()\n",
    "                Q_updated[state, action] = new_Q_value\n",
    "            if new_probability_data / old_probability < 1:\n",
    "                prob = new_probability_data / old_probability / 2\n",
    "            else:\n",
    "                prob = new_probability_data / old_probability\n",
    "\n",
    "            if np.random.random() < min(1, prob):\n",
    "                better = True\n",
    "                self.best_rewards = new_rewards_matrix\n",
    "            self.conv += 1\n",
    "\n",
    "\n",
    "\n",
    "    def simulate(self, beta_match, beta_no_match):\n",
    "\n",
    "        Q_values = torch.tensor(self.best_rewards, requires_grad=True, device=device)\n",
    "        Q_updated = Q_values.clone()\n",
    "        loss = 0\n",
    "        probability_data = 1\n",
    "        for i in range(1, len(self.states)):\n",
    "            state = self.states[i]\n",
    "            action = self.actions[i]\n",
    "            reward = self.list_rewards[i-1]  # Assuming rewards align with states/actions\n",
    "            probabilities = torch.nn.functional.softmax(Q_updated, dim=1)\n",
    "            selected_probability = probabilities[state].gather(0, action)\n",
    "            probability_data *= selected_probability\n",
    "            loss -= torch.log(selected_probability)\n",
    "            beta = beta_no_match if self.states[i-1] == 0 else beta_match\n",
    "            new_Q_value = beta * (Q_updated[state, action].clone() - reward) + Q_updated[state, action].clone()\n",
    "            Q_updated[state, action] = new_Q_value\n",
    "\n",
    "        return loss, Q_updated,probability_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T21:44:36.069500200Z",
     "start_time": "2024-06-06T21:44:36.052467Z"
    }
   },
   "id": "82474573a9f5cacf",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def optimize_participant(participant_index, states, actions, n_states, n_actions):\n",
    "    start_time = time.time()\n",
    "    initial_rewards = np.random.uniform(-3, 3, (n_states, n_actions))\n",
    "    optimizer = ParticipantOptimizer(states, actions, n_states, n_actions, initial_rewards)\n",
    "    optimizer.optimize()\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"Participant {participant_index} completed in {execution_time:.2f} seconds\")\n",
    "    return participant_index, optimizer.best_rewards, optimizer.beta_match.item(), optimizer.beta_no_match.item(), execution_time\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T21:44:36.515099800Z",
     "start_time": "2024-06-06T21:44:36.502479Z"
    }
   },
   "id": "80c4cc97383787b2",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_loader = DataLoader('RETOS_BEBRASK_long.xlsx')\n",
    "actions_dataset, states_dataset = data_loader.get_datasets('Rating0', 'Fulfilled')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T21:44:38.301333500Z",
     "start_time": "2024-06-06T21:44:36.880907900Z"
    }
   },
   "id": "533561ea14b1a405",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming data for each subject is grouped together\n",
    "batches_per_subject = 5\n",
    "\n",
    "# Dictionary to hold training and testing data for cross-validation\n",
    "cross_val_data = {}\n",
    "\n",
    "# Use enumerate to get index and subject data from actions and states datasets\n",
    "for i, (actions, states) in enumerate(zip(actions_dataset.values, states_dataset.values)):\n",
    "    num_actions = len(actions)\n",
    "    batch_size = num_actions // batches_per_subject\n",
    "    cross_val_data[i] = []\n",
    "\n",
    "    for j in range(batches_per_subject):\n",
    "        start_index = j * batch_size\n",
    "        if j == batches_per_subject - 1:\n",
    "            end_index = num_actions  # Ensure the last batch goes up to the end\n",
    "        else:\n",
    "            end_index = start_index + batch_size\n",
    "        \n",
    "        # Test data for the current fold\n",
    "        test_data = (states[start_index:end_index], actions[start_index:end_index])\n",
    "\n",
    "        # Training data for the current fold\n",
    "        # Combine slices before and after the test segment\n",
    "        train_states = np.concatenate((states[:start_index], states[end_index:]))\n",
    "        train_actions = np.concatenate((actions[:start_index], actions[end_index:]))\n",
    "        train_data = (train_states, train_actions)\n",
    "\n",
    "        # Save the train and test data in the dictionary\n",
    "        cross_val_data[i].append((train_data, test_data))\n",
    "\n",
    "# Now, `cross_val_data` is ready for use in your training/testing loops\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T21:44:38.333061700Z",
     "start_time": "2024-06-06T21:44:38.312719200Z"
    }
   },
   "id": "8760a3c1dfa1c40d",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class ParticipantOptimizerEval:\n",
    "    def __init__(self, train_states,train_actions,test_states,test_actions,n_states,n_actions, initial_rewards, Rmin=-3, Rmax=3):\n",
    "        self.train_states = torch.tensor(train_states, dtype=torch.int64, device=device)\n",
    "        self.train_actions = torch.tensor(train_actions, dtype=torch.int64, device=device)\n",
    "        self.test_states = torch.tensor(test_states, dtype=torch.int64, device=device)\n",
    "        self.test_actions = torch.tensor(test_actions, dtype=torch.int64, device=device)\n",
    "\n",
    "        self.n_states = n_states\n",
    "        self.n_actions = n_actions\n",
    "\n",
    "        self.best_rewards = initial_rewards\n",
    "        self.Rmin = Rmin\n",
    "        self.Rmax = Rmax\n",
    "\n",
    "        self.conv = 0\n",
    "\n",
    "        self.list_rewards_train = None\n",
    "        self.list_rewards_test = None\n",
    "        self.old_rewards = self.list_rewards_train\n",
    "\n",
    "        self.beta_no_match = None\n",
    "        self.beta_match = None\n",
    "        \n",
    "        self.epoch_train_losses = []\n",
    "        self.epoch_test_losses = []\n",
    "\n",
    "    def calculate_rewards_individual(self, states, actions, rewards_matrix):\n",
    "        rewards_tensor = torch.tensor(rewards_matrix, device=device)\n",
    "        probabilities = torch.nn.functional.softmax(rewards_tensor[states], dim=1)\n",
    "        selected_probabilities = probabilities.gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "        loss = -torch.sum(torch.log(selected_probabilities))\n",
    "        return loss, rewards_tensor\n",
    "\n",
    "    def find_initial_rewards(self, num_trials=200):\n",
    "        best_loss = float('inf')\n",
    "        best_rewards = None\n",
    "\n",
    "        for _ in range(num_trials):\n",
    "            trial_rewards = np.random.uniform(self.Rmin, self.Rmax, (self.n_states, self.n_actions))\n",
    "            loss, _ = self.calculate_rewards_individual(self.train_states, self.train_actions, trial_rewards)\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_rewards = trial_rewards\n",
    "        self.best_rewards = best_rewards\n",
    "\n",
    "\n",
    "    def _get_rewards_list_train(self, rewards =None):\n",
    "        if rewards is None:\n",
    "            rewards = self.best_rewards\n",
    "\n",
    "        rewards_list = []\n",
    "        for state, action in zip(self.train_states, self.train_actions):\n",
    "            rewards_list.append(rewards[state][action])\n",
    "\n",
    "        self.list_rewards_train = torch.tensor(rewards_list, dtype=torch.float32)\n",
    "        \n",
    "    def _get_rewards_list_test(self, rewards =None):\n",
    "        if rewards is None:\n",
    "            rewards = self.best_rewards\n",
    "\n",
    "        rewards_list = []\n",
    "        for state, action in zip(self.test_states, self.test_actions):\n",
    "            rewards_list.append(rewards[state][action])\n",
    "\n",
    "        self.list_rewards_test = torch.tensor(rewards_list, dtype=torch.float32)\n",
    "\n",
    "\n",
    "    def optimize(self, num_iterations=100, learning_rate=0.05):\n",
    "\n",
    "\n",
    "        self.find_initial_rewards()\n",
    "\n",
    "        for m in range(num_iterations):\n",
    "            beta_unconstrained_match = torch.tensor([-2.8], requires_grad=True, device=device)\n",
    "            beta_unconstrained_no_match = torch.tensor([-2.8], requires_grad=True, device=device)\n",
    "            optimizer = optim.Adam([beta_unconstrained_match, beta_unconstrained_no_match], lr=learning_rate)\n",
    "            self._get_rewards_list_train()\n",
    "            for epoch in range(125):\n",
    "                optimizer.zero_grad()\n",
    "                beta_match = torch.sigmoid(beta_unconstrained_match)\n",
    "                beta_no_match = torch.sigmoid(beta_unconstrained_no_match)\n",
    "\n",
    "                loss, _, probability_data= self.simulate(self.train_states, self.train_actions,self.list_rewards_train, beta_match, beta_no_match)\n",
    "                loss.backward()\n",
    "                \n",
    "                optimizer.step()\n",
    "            self.epoch_train_losses.append(loss.item()/36)\n",
    "            \n",
    "            self._get_rewards_list_test()\n",
    "\n",
    "            test_loss, _, _ = self.simulate(self.test_states, self.test_actions, self.list_rewards_test, beta_match, beta_no_match)\n",
    "            self.epoch_test_losses.append(test_loss.item()/9)            \n",
    "            \n",
    "            self.RandomWalk(0.05,beta_match,beta_no_match,probability_data)\n",
    "            if (self.conv == 50):\n",
    "                break\n",
    "\n",
    "        self.beta_match = beta_match\n",
    "        self.beta_no_match = beta_no_match\n",
    "\n",
    "\n",
    "    def perturb_rewards(self, scale=0.02):\n",
    "        perturbation = np.random.uniform(-scale, scale, self.best_rewards.shape)\n",
    "        new_rewards = np.clip(self.best_rewards + perturbation, self.Rmin, self.Rmax)\n",
    "        return new_rewards\n",
    "    \n",
    "    def RandomWalk(self, distance, beta_match, beta_no_match, old_probability):\n",
    "        better = False\n",
    "        self.old_rewards = self.list_rewards_train\n",
    "        self.conv = 0\n",
    "        while(not better and self.conv < 50):\n",
    "            new_rewards_matrix = self.perturb_rewards(distance)\n",
    "            self._get_rewards_list_train(new_rewards_matrix)\n",
    "\n",
    "            Q_values = torch.tensor(new_rewards_matrix, requires_grad=True, device=device)\n",
    "            Q_updated = Q_values.clone()\n",
    "            new_probability_data = 1\n",
    "            new_loss = 0\n",
    "\n",
    "            for i in range(1, len(self.train_states)):\n",
    "\n",
    "                state = self.train_states[i]\n",
    "                action = self.train_actions[i]\n",
    "                reward = self.list_rewards_train[i - 1]\n",
    "                # Update Q_values on a new tensor to avoid in-place operations\n",
    "                probabilities = torch.nn.functional.softmax(Q_updated, dim=1)  # Assuming Q_updated is indexed appropriately\n",
    "                selected_probability = probabilities[state].gather(0, action)\n",
    "                new_probability_data *= selected_probability\n",
    "                new_loss -= torch.log(selected_probability)\n",
    "\n",
    "                ## Maybe different beta for sequence s0->s0, s0->s1, s1->s0, s1->s1\n",
    "                if (self.train_states[i - 1] == 0):\n",
    "                    beta = beta_no_match\n",
    "                else:\n",
    "                    beta = beta_match\n",
    "                new_Q_value = beta * (Q_updated[state, action].clone() - reward) + Q_updated[state, action].clone()\n",
    "                Q_updated[state, action] = new_Q_value\n",
    "            if new_probability_data / old_probability < 1:\n",
    "                prob = new_probability_data / old_probability / 2\n",
    "            else:\n",
    "                prob = new_probability_data / old_probability\n",
    "\n",
    "            if np.random.random() < min(1, prob):\n",
    "                better = True\n",
    "                self.best_rewards = new_rewards_matrix\n",
    "            self.conv += 1\n",
    "\n",
    "\n",
    "\n",
    "    def simulate(self, states,actions,rewards,beta_match, beta_no_match):\n",
    "\n",
    "        Q_values = torch.tensor(self.best_rewards, requires_grad=True, device=device)\n",
    "        Q_updated = Q_values.clone()\n",
    "        loss = 0\n",
    "        probability_data = 1\n",
    "        \n",
    "        for i in range(1, len(states)):\n",
    "            state = states[i]\n",
    "            action = actions[i]\n",
    "            reward = rewards[i-1]  # Assuming rewards align with states/actions\n",
    "            probabilities = torch.nn.functional.softmax(Q_updated, dim=1)\n",
    "            selected_probability = probabilities[state].gather(0, action)\n",
    "            probability_data *= selected_probability\n",
    "            loss -= torch.log(selected_probability)\n",
    "            beta = beta_no_match if states[i-1] == 0 else beta_match\n",
    "            new_Q_value = beta * (Q_updated[state, action].clone() - reward) + Q_updated[state, action].clone()\n",
    "            Q_updated[state, action] = new_Q_value\n",
    "\n",
    "        return loss, Q_updated,probability_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T21:44:38.738342400Z",
     "start_time": "2024-06-06T21:44:38.717566300Z"
    }
   },
   "id": "5e511b479352afa6",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for Subject 0\n"
     ]
    }
   ],
   "source": [
    "subject_losses = []\n",
    "for subject, data_splits in cross_val_data.items():\n",
    "    if subject == 1:\n",
    "        break\n",
    "    print(f\"Training for Subject {subject}\")\n",
    "    epoch_train_losses = []\n",
    "    epoch_test_losses = []\n",
    "    \n",
    "    for fold, ((train_states, train_actions), (test_states, test_actions)) in enumerate(data_splits):\n",
    "        initial_rewards = np.random.uniform(-3, 3, (2, 4))\n",
    "        optimizer = ParticipantOptimizerEval(train_states,train_actions,test_states,test_actions,  2, 4, initial_rewards)\n",
    "        optimizer.optimize()\n",
    "        epoch_train_losses.append(optimizer.epoch_train_losses)\n",
    "        epoch_test_losses.append(optimizer.epoch_test_losses)\n",
    "    \n",
    "    subject_losses.append([epoch_train_losses,epoch_test_losses])\n",
    "        \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T12:25:13.088518600Z",
     "start_time": "2024-06-07T12:12:55.421040200Z"
    }
   },
   "id": "c9208c0651ccf634",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "lines",
         "name": "Train Loss",
         "y": [
          0.9853820597402582,
          0.984874445730048,
          0.9824237792040792,
          0.9810361484849894,
          0.9790350076486283,
          0.9763319413865063,
          0.9740325522289839,
          0.9764487830090118,
          0.9746651657073044,
          0.9736360510915733,
          0.9743748501165171,
          0.9725427993950214,
          0.9751530176461713,
          0.9745673614159365,
          0.9764131946465536,
          0.9746880180052871,
          0.9744758508246306,
          0.9731735238861953,
          0.972761660898868,
          0.9728024934892916,
          0.9723828793584863,
          0.9704876033138398,
          0.9676514594998984,
          0.9669737400991686,
          0.9676474081057027,
          0.9670368800166156,
          0.9658282159884337,
          0.9656774510396586,
          0.96254196860287,
          0.9619891131985702,
          0.9626109740029536,
          0.9618282483154384,
          0.9611562131548043,
          0.9586705542219194,
          0.9568561025668698,
          0.9567698609034562,
          0.9556924535861168,
          0.9541355605112137,
          0.9528671836333988,
          0.9537499494036524,
          0.9513267529596613,
          0.9498487376726379,
          0.9501483503704014,
          0.9510681161028176,
          0.9511571442820724,
          0.9499180041096332,
          0.9498672961760792,
          0.9485470625667141,
          0.9479464371414638,
          0.9475404461569179,
          0.9467278165292925,
          0.945727262685596,
          0.9450323654354122,
          0.9447111139624947,
          0.9445927432346164,
          0.9418740499570507,
          0.9403279529628168,
          0.9422468887404524,
          0.9419739324283221,
          0.9444246047902988,
          0.9429784341289309,
          0.9414641135757602,
          0.9419423016143735,
          0.9436557024478661,
          0.9426687730910299,
          0.9420614497737325,
          0.9430343569817404,
          0.9407375554504235,
          0.9399518780119107,
          0.9408948179393548,
          0.9402520672837185,
          0.9420425281494254,
          0.9420249022884718,
          0.9405230418672929,
          0.9408246393153818,
          0.9386490235139874,
          0.9367743091582241,
          0.9346472210481114,
          0.9340327305875338,
          0.9325760343975326,
          0.9325388116020955,
          0.9326961025831235,
          0.9321129901389261,
          0.9315960836308562,
          0.931365201941311,
          0.930959061003761,
          0.9295741710144956,
          0.930011596442065,
          0.9315144159944262,
          0.9339092320794931,
          0.9327977097797706,
          0.9328785718998919,
          0.9316524642384711,
          0.9317840261310743,
          0.9329288443792587,
          0.9343686693837412,
          0.9328402623713405,
          0.9329928041894495,
          0.9312894421503414,
          0.9312092898807947
         ],
         "type": "scatter"
        },
        {
         "mode": "lines",
         "name": "Test Loss",
         "y": [
          1.0884478082802373,
          1.089790446391243,
          1.0895399857439145,
          1.0919288060161414,
          1.0935869969705192,
          1.0921727282553868,
          1.0949831577999922,
          1.1009998513682473,
          1.1001994760104086,
          1.0954191115023075,
          1.0935023465785139,
          1.0989660744645935,
          1.1007842016938085,
          1.1025833135203793,
          1.1115223923532365,
          1.1089895211006986,
          1.1094677455538418,
          1.1085819828351475,
          1.108278068962265,
          1.1061191855350068,
          1.1063258430731184,
          1.1061036281298178,
          1.1040799665628063,
          1.1031476103796534,
          1.1034655816877763,
          1.1023776901887457,
          1.0977576806166092,
          1.1020307394031255,
          1.1037356475572815,
          1.1053884510547716,
          1.1051361041481171,
          1.1038088470799265,
          1.1027769434647068,
          1.1058905429405743,
          1.1053307465570459,
          1.105800619607321,
          1.1040699560542875,
          1.0998411038461549,
          1.0962544955018259,
          1.0942824171787038,
          1.0939756128488418,
          1.0942766518905445,
          1.0975914336655004,
          1.1009872321525092,
          1.1005996189483964,
          1.1011396574953873,
          1.1025085907326875,
          1.1038586483361148,
          1.107355572478999,
          1.0995806820348342,
          1.1041434745212175,
          1.099083737765736,
          1.0952955936729498,
          1.0996413400270133,
          1.0988705642527035,
          1.0978194551038285,
          1.0961803136810357,
          1.0993045966746635,
          1.0944300928985453,
          1.1010430938475138,
          1.1003210541343382,
          1.0996052645768128,
          1.098159441248844,
          1.1015323643589774,
          1.1004483351212098,
          1.0955273775746146,
          1.0991547972721871,
          1.0939068628448154,
          1.0944206104020668,
          1.0959346822168108,
          1.098308739612384,
          1.1038693419422887,
          1.1055222414903194,
          1.1061062935670392,
          1.1079029369313922,
          1.1087487487286967,
          1.1046849611025795,
          1.099979019087937,
          1.097052943781917,
          1.0973919403885017,
          1.095861819611256,
          1.0972627182675594,
          1.0963168891871893,
          1.0892303291942649,
          1.0916406773808258,
          1.0943124031475775,
          1.087679942900998,
          1.0848865846077524,
          1.0871787820012464,
          1.0955686443734327,
          1.095957603702501,
          1.0900377854842178,
          1.0874977179910235,
          1.091794892370519,
          1.0873865535201102,
          1.0921340573561615,
          1.0900184586886987,
          1.0849575562555738,
          1.0794439566040528,
          1.077914549077761
         ],
         "type": "scatter"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "histogram2dcontour": [
           {
            "type": "histogram2dcontour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "choropleth": [
           {
            "type": "choropleth",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "histogram2d": [
           {
            "type": "histogram2d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmap": [
           {
            "type": "heatmap",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmapgl": [
           {
            "type": "heatmapgl",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "contourcarpet": [
           {
            "type": "contourcarpet",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "contour": [
           {
            "type": "contour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "surface": [
           {
            "type": "surface",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "mesh3d": [
           {
            "type": "mesh3d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "parcoords": [
           {
            "type": "parcoords",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolargl": [
           {
            "type": "scatterpolargl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "scattergeo": [
           {
            "type": "scattergeo",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolar": [
           {
            "type": "scatterpolar",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scatter3d": [
           {
            "type": "scatter3d",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattermapbox": [
           {
            "type": "scattermapbox",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterternary": [
           {
            "type": "scatterternary",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattercarpet": [
           {
            "type": "scattercarpet",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ]
         },
         "layout": {
          "autotypenumbers": "strict",
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "hovermode": "closest",
          "hoverlabel": {
           "align": "left"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "bgcolor": "rgb(17,17,17)",
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "ternary": {
           "bgcolor": "rgb(17,17,17)",
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "sequential": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ]
          },
          "xaxis": {
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "automargin": true,
           "zerolinewidth": 2
          },
          "yaxis": {
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "automargin": true,
           "zerolinewidth": 2
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3",
            "gridwidth": 2
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3",
            "gridwidth": 2
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3",
            "gridwidth": 2
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "subunitcolor": "#506784",
           "showland": true,
           "showlakes": true,
           "lakecolor": "rgb(17,17,17)"
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "borderwidth": 1,
           "bordercolor": "rgb(17,17,17)",
           "tickwidth": 0
          },
          "mapbox": {
           "style": "dark"
          }
         }
        },
        "title": {
         "text": "Loss Evolution Over Epochs",
         "font": {
          "color": "black"
         }
        },
        "font": {
         "color": "black"
        },
        "xaxis": {
         "title": {
          "text": "Epoch",
          "font": {
           "color": "black"
          }
         },
         "tickfont": {
          "color": "black"
         }
        },
        "yaxis": {
         "title": {
          "text": "Loss",
          "font": {
           "color": "black"
          }
         },
         "tickfont": {
          "color": "black"
         }
        },
        "legend": {
         "title": {
          "text": "Legend",
          "font": {
           "color": "black"
          }
         },
         "font": {
          "color": "black"
         }
        },
        "plot_bgcolor": "white",
        "paper_bgcolor": "white"
       },
       "config": {
        "plotlyServerURL": "https://plot.ly"
       }
      },
      "text/html": "<div>                            <div id=\"59340542-423b-4853-9e77-08a2ea0b1866\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"59340542-423b-4853-9e77-08a2ea0b1866\")) {                    Plotly.newPlot(                        \"59340542-423b-4853-9e77-08a2ea0b1866\",                        [{\"mode\":\"lines\",\"name\":\"Train Loss\",\"y\":[0.9853820597402582,0.984874445730048,0.9824237792040792,0.9810361484849894,0.9790350076486283,0.9763319413865063,0.9740325522289839,0.9764487830090118,0.9746651657073044,0.9736360510915733,0.9743748501165171,0.9725427993950214,0.9751530176461713,0.9745673614159365,0.9764131946465536,0.9746880180052871,0.9744758508246306,0.9731735238861953,0.972761660898868,0.9728024934892916,0.9723828793584863,0.9704876033138398,0.9676514594998984,0.9669737400991686,0.9676474081057027,0.9670368800166156,0.9658282159884337,0.9656774510396586,0.96254196860287,0.9619891131985702,0.9626109740029536,0.9618282483154384,0.9611562131548043,0.9586705542219194,0.9568561025668698,0.9567698609034562,0.9556924535861168,0.9541355605112137,0.9528671836333988,0.9537499494036524,0.9513267529596613,0.9498487376726379,0.9501483503704014,0.9510681161028176,0.9511571442820724,0.9499180041096332,0.9498672961760792,0.9485470625667141,0.9479464371414638,0.9475404461569179,0.9467278165292925,0.945727262685596,0.9450323654354122,0.9447111139624947,0.9445927432346164,0.9418740499570507,0.9403279529628168,0.9422468887404524,0.9419739324283221,0.9444246047902988,0.9429784341289309,0.9414641135757602,0.9419423016143735,0.9436557024478661,0.9426687730910299,0.9420614497737325,0.9430343569817404,0.9407375554504235,0.9399518780119107,0.9408948179393548,0.9402520672837185,0.9420425281494254,0.9420249022884718,0.9405230418672929,0.9408246393153818,0.9386490235139874,0.9367743091582241,0.9346472210481114,0.9340327305875338,0.9325760343975326,0.9325388116020955,0.9326961025831235,0.9321129901389261,0.9315960836308562,0.931365201941311,0.930959061003761,0.9295741710144956,0.930011596442065,0.9315144159944262,0.9339092320794931,0.9327977097797706,0.9328785718998919,0.9316524642384711,0.9317840261310743,0.9329288443792587,0.9343686693837412,0.9328402623713405,0.9329928041894495,0.9312894421503414,0.9312092898807947],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Test Loss\",\"y\":[1.0884478082802373,1.089790446391243,1.0895399857439145,1.0919288060161414,1.0935869969705192,1.0921727282553868,1.0949831577999922,1.1009998513682473,1.1001994760104086,1.0954191115023075,1.0935023465785139,1.0989660744645935,1.1007842016938085,1.1025833135203793,1.1115223923532365,1.1089895211006986,1.1094677455538418,1.1085819828351475,1.108278068962265,1.1061191855350068,1.1063258430731184,1.1061036281298178,1.1040799665628063,1.1031476103796534,1.1034655816877763,1.1023776901887457,1.0977576806166092,1.1020307394031255,1.1037356475572815,1.1053884510547716,1.1051361041481171,1.1038088470799265,1.1027769434647068,1.1058905429405743,1.1053307465570459,1.105800619607321,1.1040699560542875,1.0998411038461549,1.0962544955018259,1.0942824171787038,1.0939756128488418,1.0942766518905445,1.0975914336655004,1.1009872321525092,1.1005996189483964,1.1011396574953873,1.1025085907326875,1.1038586483361148,1.107355572478999,1.0995806820348342,1.1041434745212175,1.099083737765736,1.0952955936729498,1.0996413400270133,1.0988705642527035,1.0978194551038285,1.0961803136810357,1.0993045966746635,1.0944300928985453,1.1010430938475138,1.1003210541343382,1.0996052645768128,1.098159441248844,1.1015323643589774,1.1004483351212098,1.0955273775746146,1.0991547972721871,1.0939068628448154,1.0944206104020668,1.0959346822168108,1.098308739612384,1.1038693419422887,1.1055222414903194,1.1061062935670392,1.1079029369313922,1.1087487487286967,1.1046849611025795,1.099979019087937,1.097052943781917,1.0973919403885017,1.095861819611256,1.0972627182675594,1.0963168891871893,1.0892303291942649,1.0916406773808258,1.0943124031475775,1.087679942900998,1.0848865846077524,1.0871787820012464,1.0955686443734327,1.095957603702501,1.0900377854842178,1.0874977179910235,1.091794892370519,1.0873865535201102,1.0921340573561615,1.0900184586886987,1.0849575562555738,1.0794439566040528,1.077914549077761],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#f2f5fa\"},\"error_y\":{\"color\":\"#f2f5fa\"},\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scattergl\"}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"baxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#506784\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"header\":{\"fill\":{\"color\":\"#2a3f5f\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#f2f5fa\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"rgb(17,17,17)\",\"plot_bgcolor\":\"rgb(17,17,17)\",\"polar\":{\"bgcolor\":\"rgb(17,17,17)\",\"angularaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"rgb(17,17,17)\",\"aaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#f2f5fa\"}},\"annotationdefaults\":{\"arrowcolor\":\"#f2f5fa\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"rgb(17,17,17)\",\"landcolor\":\"rgb(17,17,17)\",\"subunitcolor\":\"#506784\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"rgb(17,17,17)\"},\"title\":{\"x\":0.05},\"updatemenudefaults\":{\"bgcolor\":\"#506784\",\"borderwidth\":0},\"sliderdefaults\":{\"bgcolor\":\"#C8D4E3\",\"borderwidth\":1,\"bordercolor\":\"rgb(17,17,17)\",\"tickwidth\":0},\"mapbox\":{\"style\":\"dark\"}}},\"title\":{\"text\":\"Loss Evolution Over Epochs\",\"font\":{\"color\":\"black\"}},\"font\":{\"color\":\"black\"},\"xaxis\":{\"title\":{\"text\":\"Epoch\",\"font\":{\"color\":\"black\"}},\"tickfont\":{\"color\":\"black\"}},\"yaxis\":{\"title\":{\"text\":\"Loss\",\"font\":{\"color\":\"black\"}},\"tickfont\":{\"color\":\"black\"}},\"legend\":{\"title\":{\"text\":\"Legend\",\"font\":{\"color\":\"black\"}},\"font\":{\"color\":\"black\"}},\"plot_bgcolor\":\"white\",\"paper_bgcolor\":\"white\"},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('59340542-423b-4853-9e77-08a2ea0b1866');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "for i in range(0,1): \n",
    "    print(f'Subject {i}')\n",
    "    train_losses = np.mean(np.array(subject_losses[i][0]), axis=0)\n",
    "    test_losses = np.mean(np.array(subject_losses[i][1]), axis=0)\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(y=train_losses, mode='lines', name='Train Loss'))\n",
    "    fig.add_trace(go.Scatter(y=test_losses, mode='lines', name='Test Loss'))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        plot_bgcolor='white',\n",
    "        paper_bgcolor='white',\n",
    "        title='Loss Evolution Over Epochs',\n",
    "        xaxis_title='Epoch',\n",
    "        yaxis_title='Loss',\n",
    "        legend_title='Legend',\n",
    "        title_font_color=\"black\",\n",
    "        font=dict(color=\"black\"),  # Sets global font color to black, affecting most text elements\n",
    "        xaxis=dict(\n",
    "            title_font=dict(color=\"black\"),\n",
    "            tickfont=dict(color=\"black\")  # Sets x-axis tick labels to black\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title_font=dict(color=\"black\"),\n",
    "            tickfont=dict(color=\"black\")  # Sets y-axis tick labels to black\n",
    "        ),\n",
    "        legend_title_font_color=\"black\",\n",
    "        legend=dict(\n",
    "            font=dict(color=\"black\")  # Sets legend text to black\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T12:25:13.134519800Z",
     "start_time": "2024-06-07T12:25:13.102475100Z"
    }
   },
   "id": "d9bdeede82bb128e",
   "execution_count": 36
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
